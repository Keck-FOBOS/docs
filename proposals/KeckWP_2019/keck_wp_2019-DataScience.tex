%%%%
% -- Data Science
% --     FOBOS Keck White Paper 2019
%%%%

\subsection{FOBOS as an ideal spectroscopic training instrument}
\label{sec:datascience}

FOBOS enables Keck to play a significant role in the ``Big Data'' era of LSST and other panoramic surveys by serving as the world's premier spectroscopic \emph{training} facility.  As machine learning techniques advance in the coming decade,  spectroscopic ``training'' as a means of extracting the maximum information from billions of photometric sources across thousands of deg$^2$ becomes increasingly important.  The Keck telescopes were optimized for 10--20 arcmin fields, making them ill-suited to wide-field instruments capable of direct, panoramic followup.  But the required training samples at LSST depths will fill even the modest Keck focal plane with 10's of thousands of sources.  The key requirements are sensitivity and multiplex (not field-of-view).  Emphasizing these, FOBOS will be ideal training facility for LSST-era photometric redshifts \citep[see][]{salvato19}, galaxy physical properties \citep[e.g.,][]{davidzon19}, and stellar parameters \citep[e.g.,][]{2018arXiv180401530T}.


% Above, we have focused on specific studies that directly benefit from
% FOBOS's capabilities. However, FOBOS will also allow teams of Keck
% scientists to quickly build spectoscopic samples purposely designed
% to be used as spectroscopic training sets. Here, we highlight two
% cases where well-designed FOBOS observations can be used in novel
% machine-learning applications.

% These data will allow us to statistically infer physical properties
% from upcoming large-scale broad-band imaging surveys (e.g., LSST,
% WFIRST, Euclid) that are only directly accessible via spectroscopy
% and complement more shallow spectroscopic surveys made with FOBOS or
% surveys using smaller aperture facilities (e.g., APOGEE, DESI).
% Keying off one of NSF's ten Big Ideas, we highlight a few ways that
% FOBOS can be used to "harness the data revolution."

% \begin{figure}[h!]
% \vskip -0.1in
% \includegraphics[width=\textwidth]{figs/LGplots.pdf}
% \caption{{\it Left}: Validation of {\it The Cannon} measurements of
% stellar effective temperature, $T_{\rm eff}$, and surface gravity,
% $\log g$, using low-resolution LAMOST spectra (left) compared to
% high-resolution APOGEE measurements
% \citep[right;][]{2017ApJ...836....5H}. {\it Top-right}: Recovery of
% elemental abundances from low-resolution LAMOST spectra compared to
% high-resolution measurements from GALAH (Xiang et al., in prep). {\it
% Bottom-right}: The circular-speed curve of the Milky Way determined
% using a data-driven model that combines stellar parameters determined
% from APOGEE spectra with photometry from WISE, 2MASS, and Gaia
% \citep{2019ApJ...871..120E}. FOBOS will be a premier instrument for
% such machine-learning applications.}
% \label{fig:Cannon}
% \end{figure}

% \subsubsection{The chemical evolution of Milky Way stellar
% populations} Kinematics and chemical-abundance measurements for stars
% in the MW halo or the M31 disk require observations of 10 hours or
% more on large telescopes \citep[e.g.,][]{2018arXiv180904082C}.
% However, machine-learning algorithms can be used to extract physical
% quantities from both multi-band imaging and lower quality spectra
% (low resolution and S/N) using relatively small, high-S/N, training
% sets (e.g., Fig.~\ref{fig:Cannon}). The goal of such applications is
% to reach magnitudes significantly fainter than the detection limit of
% current and upcoming spectroscopic surveys by designing an optimized,
% nested set of FOBOS training samples. This nested set will vary in
% S/N and spectral resolution for sufficiently large, overlapping
% stellar samples, and include astroseismology from TESS and PLATO for
% some subset. Within this nested set, low-resolution FOBOS data will
% fill gaps at both high-S/N, where we can train FOBOS data on
% higher resolution spectroscopy, and low-S/N, where we will
% be training photometry on FOBOS spectroscopy. The success of this
% multi-layered inference depends not only on the size of the training
% sets we can access or observe, but on how representative they are.
% For example, inference of M31 halo stellar properties from WFIRST
% photometry based on a MW-trained set of FOBOS spectroscopy will
% require accuracy assessments using simulated data.

% For example, \citet{2015ApJ...808...16N} have developed {\it The
% Cannon}, a supervised learning approach that uses spectra with known
% stellar parameters to label spectra where those parameters are
% unknown (Fig.~\ref{fig:Cannon}). Additionally,
% \citet{2018arXiv180401530T} have developed {\it The Payne} which can
% infer 16 stellar-abundance labels from low-resolution spectra using a
% neural network and theoretical stellar spectra. Finally,
% \citet{2018arXiv180803278T} have combined Kepler-based
% astroseismology measurements with APOGEE spectra to determine stellar
% age to $\sim$25\% precision using a neural network. Our proposed
% effort builds on new lines of inquiry based on these successes.

% of the Milky Way including Gaia, APOGEE, the SDSS-V Milky Way Mapper,
% planned programs with 4MOST and the Dark Energy Spectroscopic
% Instrument (DESI) Milky Way Survey, among others. Inferring stellar
% parameters beyond $V$$\sim$18 will open up studies of the Milk Wayâ€™s
% outer halo, the halo of M31, and stellar populations in local dwarf
% galaxies.

% Using simulated spectra with known input parameters, we will test
% methods for ``label transfer'' from information-rich spectra to
% information-poor spectra as we work down to fainter magnitudes,
% landing eventually at multi-band photometry alone.

% We will test it by evaluating label recovery on simulated stellar
% spectra with cosmologically-informed formation histories for M31 and
% dwarf galaxies, suitably differentiated from the Milky Way stars that
% anchor the training network.

% \subsubsection{The $z$$\sim$2 Galaxy Population}

% \begin{figure}[h!]
% \vskip -0.1in
% \includegraphics[width=\textwidth]{figs/Hemmati18_Fig8_VVDS_spec.png}
% \caption{\small {\it Left}: A Self-Organizing Map
% \citep[SOM;][]{1990Natur.346...24K} from \citet{hemmati18}, which
% encodes the relation between galaxy colors in an LSST+WFIRST-like
% color space and their redshift, $z$. Such SOMs can be used to
% optimally define FOBOS spectroscopic training samples for use with
% imaging surveys to populate sparsely sampled regions. {\it Right}:
% Galaxy spectra from VVDS \citep{2005A&A...439..845L}; black crosses
% near the top and bottom of the SOM are plotted in the top and bottom
% panels, respectively. The detailed similarity of spectral features of
% galaxies localized within the SOM suggests a systematic spectroscopic
% exploration with FOBOS of the LSST color space allows for inference
% of galaxy physical properties beyond a photo-$z$ training
% application.}
% \label{fig:SOM}
% \end{figure}

% % Galaxies observed in this space are assigned $z$ values based on the
% % median photo-$z$ of galaxies from the CANDELS survey \citep[color
% % bar;][]{2011ApJS..197...35G}.

% For decades, we have used the spectral information encoded in
% broad-band photometry to infer properties of galaxies beyond their
% color and brightness. The most common application is to estimate the
% galaxy redshift, i.e. photometric redshifts (photo-$z$s). However, a
% range of observed spectral features are well-constrained by
% broad-band imaging (Fig. \ref{fig:SOM}), suggesting a far greater
% potential for imaging data to reveal physical properties with
% sufficient training of deep-learning algorithms. Self-Organizing Maps
% (SOM, Figure \ref{fig:SOM}) provide a state-of-the-art representation
% of a high-dimensional input space in projected 2D grid cells,
% allowing us to benchmark sampling of the photometric color space
% under various training set designs. The compelling prospect of this
% approach is its utility in delivering SDSS-like information --- e.g.,
% star-formation histories, stellar-population properties, dust
% content, inflow/outflow properties, and stellar masses --- for
% the millions of galaxies imaged by LSST at $z$$\sim$2.

% These properties go beyond what conventional modeling of spectral
% energy distributions (SEDs) would suggest.

% We will also use Bayesian Optimization techniques to evaluate the
% success of simulated training sets against the fidelity of full
% cosmological analyses that employ them. This will enable extremely
% rapid exploration of the optimal design space.

%\comment{Masters, Mandelbaum, Rau, Schafer}

% The complete photo-$z$ training survey described in \citet{newman15}
% would require 15 independent pointings, each spanning 0.1 deg$^2$ with
% a target density of 6 arcmin$^{-2}$ (8 arcmin$^{-2}$ when including $z
% > 1.5$ galaxies accessible in the UV with Keck-FOBOS), perfectly
% matched to the Keck-FOBOS field-of-view and target density.  With a
% conservative exposure time of 100 hours to reach 75\% redshift
% completeness for 40,000 galaxies with $i_{\rm AB} < 25.3$, the Neman
% survey would require 400 nights.  Challenge \ref{photoz} would reduce
% the required survey duration by a factor of at least four.  Meanwhile
% the extreme depths and flux-limited selection are likely also
% requirements for training sets associated with Challenges \ref{phot},
% \ref{uv}.

% A wider and shallower survey component is envisioned for Challenges
% \ref{lowsnr} and \ref{gaia}.  With 10-minute integrations, a 52
% deg$^2$ Keck-FOBOS sample of environmental diagnostics for 1 million
% galaxies could be carried out in less than 20 nights.  This program
% would sample at $z \sim 1.5$ the same cosmic volume as SDSS.  A
% program of a similar scale would provide training set data for
% inference of stellar parameters in the Milky Way.  These shallow
% programs would be integrated with the deeper components described
% above into a single survey plan.